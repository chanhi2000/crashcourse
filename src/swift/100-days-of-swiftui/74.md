---
lang: ko-KR
title: Day 74
description: üïäÔ∏è100 Days of SwiftUI > Day 74
category:
  - üïäÔ∏èSwift
tag: 
  - crashcourse
  - paul-hudson
  - swift
  - swiftui
  - hacking-with-swift
  - xcode
  - appstore
head:
  - - meta:
    - property: og:title
      content: üïäÔ∏è100 Days of SwiftUI > Day 74
    - property: og:description
      content: Day 74
    - property: og:url
      content: https://chanhi2000.github.io/crashcourse/swift/100-days-of-swiftui/74.html
---

# {{ $frontmatter.title }} Í¥ÄÎ†®

> {{ $frontmatter.description }}

[[toc]]

---

```component VPCard
title: 100 Days of SwiftUI ‚Äì Day 74
desc: Project 15, part 1
link: https://www.hackingwithswift.com/100/swiftui/74
logo: https://www.hackingwithswift.com/favicon-96x96.png
background: rgba(54,94,226,0.2)
```

## Project 15, part 1

We have a new technique project today, this time focusing on something you might not even have considered: accessibility. This is a measure of how well our app can be used by people with varying access needs ‚Äì they might need larger text, they might need us to avoid certain colors to help them see things clearly, they might need our UI to be read out, and so on.

Too many developers completely ignore the importance of accessibility, which results in apps that are completely opaque to large numbers of people. Tony Fadell ‚Äì the creator of the iPod at Apple ‚Äì had this to say: ‚Äúyou are defined by what you do and also by what you don‚Äôt do.‚Äù

Sure, you can skip accessibility and 90% of people won‚Äôt notice, but do you want to be defined by that? I‚Äôd wager that the answer is _no_.

__Today you have four topics to work through, in which you‚Äôll learn about accessibility labels, values, hints, and more.__

### Accessibility: Introduction

::: details Accessibility: Introduction

```component VPCard
title: 100 Days of SwiftUI ‚Äì Day 74 - Accessibility (Introduction)
desc: Accessibility (Introduction)
link: https://www.hackingwithswift.com/books/ios-swiftui/accessibility-introduction
logo: https://www.hackingwithswift.com/favicon-96x96.png
background: rgba(213,52,58,0.2)
```

Making your app accessible means taking steps to ensure that everyone can use it fully regardless of their individual needs. For example, if they are blind then your app should work well with the system‚Äôs VoiceOver system to ensure your UI can be read smoothly.

SwiftUI gives us a huge amount of functionality for free, because its layout system of `VStack` and `HStack` naturally forms a flow of views. However, it isn‚Äôt perfect, and any time you can add some extra information to help out the iOS accessibility system it‚Äôs likely to help.

Usually the best way to test out your app is to enable VoiceOver support and run the app on a real device ‚Äì if your app works great with VoiceOver, there‚Äôs a good chance you‚Äôre already far ahead of the average for iOS apps.

Anyway, in this technique project we‚Äôre going to look at a handful of accessibility techniques, then look at some of the previous projects we made to see how they might get upgraded.

For now, please create a new iOS app using the App template. You should run this project on a real device, so you can enable VoiceOver for real.

__Acknowledgements__: I‚Äôm grateful for the help of Robin Kipp in preparing this chapter ‚Äì he wrote in with some detailed suggestions for things he‚Äôd like to see with regards to accessibility, giving me some great examples of how it would affect his own personal use.

:::

### Identifying views with useful labels

::: details Identifying views with useful labels

```component VPCard
title: 100 Days of SwiftUI ‚Äì Day 74 - Identifying views with useful labels
desc: Identifying views with useful labels
link: https://www.hackingwithswift.com/books/ios-swiftui/identifying-views-with-useful-labels
logo: https://www.hackingwithswift.com/favicon-96x96.png
background: rgba(213,52,58,0.2)
```

<VidStack src="youtube/v7q4Y46Z3-A" />

In the files for this project I have placed four pictures downloaded from Unsplash. Unsplash filenames are made up of a picture ID and the photographer‚Äôs name, so if you drag them into your asset catalog you‚Äôll see they have names such as "ales-krivec-15949" and so on. That in itself isn‚Äôt a problem, and in fact I think it can be a helpful way of remembering where assets came from. However, it does present a problem for screen readers.

To get started with VoiceOver, we‚Äôre going to create a simple view that cycles randomly through the four pictures in our asset catalog. Modify the `ContentView` struct to this:

```swift
struct ContentView: View {
    let pictures = [
        "ales-krivec-15949",
        "galina-n-189483",
        "kevin-horstmann-141705",
        "nicolas-tissot-335096"
    ]

    @State private var selectedPicture = Int.random(in: 0...3)

    var body: some View {
        Image(pictures[selectedPicture])
            .resizable()
            .scaledToFit()
            .onTapGesture {
                selectedPicture = Int.random(in: 0...3)
            }
    }
}
```

There‚Äôs nothing complicated there, but it already helps to illustrate two serious problems.

If you haven‚Äôt already enabled VoiceOver in the Settings app on your iOS device, please do so now: Settings > Accessibility > VoiceOver, then toggle it on. Alternatively, you can activate Siri at any time and ask to enable or disable VoiceOver.

__Important__: Immediately below the VoiceOver toggle is instructions for how to use it. The regular taps and swipes you‚Äôre used to no longer function the same way, so read those instructions!

Now launch our app on your device, and try tapping once on the picture to activate it. If you listen carefully to VoiceOver you should hear two problems:

1. Reading out ‚ÄúKevin Horstmann one four one seven zero five‚Äù is not only unhelpful for the user because it doesn‚Äôt describe the picture at all, but it‚Äôs actually confusing ‚Äì the long string of numbers does more harm than good.
2. After reading the above string, VoiceOver then says ‚Äúimage‚Äù. This is true, it _is_ an image, but it‚Äôs also acting as a button because we added an `onTapGesture()` modifier.

The first of those problems is a side effect of SwiftUI trying to give us sensible behavior out of the box: when given an image, it automatically uses the image‚Äôs filename as the text to read out.

We can control what VoiceOver reads for a given view by attaching two modifiers: `.accessibilityLabel()` and `.accessibilityHint()`. They both take text containing anything we want, but they serve different purposes:

- The _label_ is read immediately, and should be a short piece of text that gets right to the point. If this view deletes an item from the user‚Äôs data, it might say ‚ÄúDelete‚Äù.
- The _hint_ is read after a short delay, and should provide more details on what the view is there for. It might say ‚ÄúDeletes an email from your inbox‚Äù, for example.

The label is exactly what we need to solve the first of our problems, because it means we can leave the image name as it is while still having VoiceOver read out something that helps users.

First, add this second array of image descriptions as a property for `ContentView`:

```swift
let labels = [
    "Tulips",
    "Frozen tree buds",
    "Sunflowers",
    "Fireworks",
]
```

And now attach this modifier to the image:

```swift
.accessibilityLabel(labels[selectedPicture])
```

This allows VoiceOver to read the correct label no matter what image is present. Of course, if your image wasn‚Äôt randomly changing you could just type your label directly into the modifier.

The second problem is that the image is identified as an image. This is self-evidently true, but it‚Äôs also not helpful because we‚Äôve attached a tap gesture to it so it‚Äôs effectively a button.

We can fix this second problem using another modifier, `.accessibilityAddTraits()`. This lets us provide some extra behind the scenes information to VoiceOver that describes how the view works, and in our case we can tell it that our image is also a button by adding this modifier:

```swift
.accessibilityAddTraits(.isButton)
```

If you wanted, you could remove the image trait as well, because it isn‚Äôt really adding much:

```swift
.accessibilityRemoveTraits(.isImage)
```

With these changes in place our UI works much better: VoiceOver now reads a useful description of the image‚Äôs contents, and also makes users aware the image is also a button.

:::

### Hiding and grouping accessibility data

::: details Hiding and grouping accessibility data

```component VPCard
title: 100 Days of SwiftUI ‚Äì Day 74 - Hiding and grouping accessibility data
desc: Hiding and grouping accessibility data
link: https://www.hackingwithswift.com/books/ios-swiftui/hiding-and-grouping-accessibility-data
logo: https://www.hackingwithswift.com/favicon-96x96.png
background: rgba(213,52,58,0.2)
```

<VidStack src="youtube/OiD1ZpMZUZ4" />

If you spend even a few minutes with an active VoiceOver user, you‚Äôll learn two things very quickly: they are remarkably adept at navigating around user interfaces, and they also often set reading speed extremely fast ‚Äì way faster than you or I would use.

It‚Äôs important to take both of those things into account when we‚Äôre designing our UI: these users aren‚Äôt just trying VoiceOver out of curiosity, but are instead VoiceOver power users who rely on it to access your app. As a result, it‚Äôs important we ensure our UI removes as much clutter as possible so that users can navigate through it quickly and not have to listen to VoiceOver reading unhelpful descriptions.

Beyond setting labels and hints, there are several ways we can control what VoiceOver reads out. There are three in particular I want to focus on:

- Marking images as being unimportant for VoiceOver.
- Hiding views from the accessibility system.
- Grouping several views as one.

All of these are simple changes to make, but they result in a big improvement.

For example, we can tell SwiftUI that a particular image is just there to make the UI look better by using `Image(decorative:)`. Whether it‚Äôs a simple bullet point or an animation of your app‚Äôs mascot character running around, it doesn‚Äôt actually convey any information and so `Image(decorative:)` tells SwiftUI it should be ignored by VoiceOver.

Use it like this:

```swift
Image(decorative: "character")
```

This leaves the image as being accessible to VoiceOver if it has some important traits, such as `.isButton` ‚Äì it will say ‚Äúbutton‚Äù when it‚Äôs highlighted, and if we attach a tap gesture that works ‚Äì but it _doesn‚Äôt_ read out the image‚Äôs filename as the automatic VoiceOver label. If you then add a label or a hint that _will_ be read.

If you want to go a step further, you can use the `.accessibilityHidden()` modifier, which makes any view completely invisible to the accessibility system:

```swift
Image(decorative: "character")
    .accessibilityHidden(true)
```

With that modifier the image becomes invisible to VoiceOver regardless of what traits it has. Obviously you should only use this if the view in question really does add nothing ‚Äì if you had placed a view offscreen so that it wasn‚Äôt currently visible to users, you should mark it inaccessible to VoiceOver too.

The last way to hide content from VoiceOver is through _grouping_, which lets us control how the system reads several views that are related. As an example, consider this layout:

```swift
VStack {
    Text("Your score is")
    Text("1000")
        .font(.title)
}
```

VoiceOver sees that as two unrelated text views, and so it will either read ‚ÄúYour score is‚Äù or ‚Äú1000‚Äù depending on what the user has selected. Both of those are unhelpful, which is where the `.accessibilityElement(children:)` modifier comes in: we can apply it to a parent view, and ask it to combine children into a single accessibility element.

For example, this will cause both text views to be read together:

```swift
VStack {
    Text("Your score is")
    Text("1000")
        .font(.title)
}
.accessibilityElement(children: .combine)
```

That works really well when the child views contain separate information, but in our case the children really should be read as a single entity. So, the better solution here is to use `.accessibilityElement(children: .ignore)` so the child views are invisible to VoiceOver, then provide a custom label to the parent, like this:

```swift
VStack {
    Text("Your score is")
    Text("1000")
        .font(.title)
}
.accessibilityElement(children: .ignore)
.accessibilityLabel("Your score is 1000")
```

It‚Äôs worth trying both of these to see how they differ in practice. Using `.combine` adds a pause between the two pieces of text, because they aren‚Äôt necessarily designed to be read together. Using `.ignore` and a custom label means the text is read all at once, and is much more natural.

__Tip__: `.ignore` is the default parameter for `children`, so you can get the same results as `.accessibilityElement(children: .ignore)` just by saying `.accessibilityElement()`.

:::

### Reading the value of controls

::: details Reading the value of controls

```component VPCard
title: 100 Days of SwiftUI ‚Äì Day 74 - Reading the value of controls
desc: Reading the value of controls
link: https://www.hackingwithswift.com/books/ios-swiftui/reading-the-value-of-controls
logo: https://www.hackingwithswift.com/favicon-96x96.png
background: rgba(213,52,58,0.2)
```

<VidStack src="youtube/JLsv4VVN6mY" />

By default SwiftUI provides VoiceOver readouts for its user interface controls, and although these are often good sometimes they just don‚Äôt fit with what you need. In these situations we can use the `accessibilityValue()` modifier to separate a control‚Äôs value from its label, but we can also specify custom swipe actions using `accessibilityAdjustableAction()`.

For example, you might build a view that shows some kind of input controlled by various buttons, like a custom stepper:

```swift
struct ContentView: View {
    @State private var value = 10

    var body: some View {
        VStack {
            Text("Value: \(value)")

            Button("Increment") {
                value += 1
            }

            Button("Decrement") {
                value -= 1
            }
        }
    }
}
```

That might work just the way you want with tap interactions, but it‚Äôs not a great experience with VoiceOver because all users will hear is ‚ÄúIncrement‚Äù or ‚ÄúDecrement‚Äù every time they tap one of the buttons.

To fix this we can give iOS specific instructions for how to handle adjustment, by grouping our `VStack` together using `accessibilityElement()` and `accessibilityLabel()`, then by adding the `accessibilityValue()` and `accessibilityAdjustableAction()` modifiers to respond to swipes with custom code.

Adjustable actions hand us the direction the user swiped, and we can respond however we want. There is one proviso: yes, we can choose between increment and decrement swipes, but we also need a special default case to handle unknown future values ‚Äì Apple has reserved the right to add other kinds of adjustments in the future.

Here‚Äôs how it looks in code:

```swift
VStack {
    Text("Value: \(value)")

    Button("Increment") {
        value += 1
    }

    Button("Decrement") {
        value -= 1
    }
}
.accessibilityElement()
.accessibilityLabel("Value")
.accessibilityValue(String(value))    
.accessibilityAdjustableAction { direction in
    switch direction {
    case .increment:
        value += 1
    case .decrement:
        value -= 1
    default:
        print("Not handled.")
    }
}
```

That lets users select the whole `VStack` to have ‚ÄúValue: 10‚Äù read out, but then they can swipe up or down to manipulate the value and have just the numbers read out ‚Äì it‚Äôs a much more natural way of working.

:::

When you‚Äôre done, try using some other apps on your phone with VoiceOver turned on ‚Äì can you find any that need some improvement?

---

<TagLinks />